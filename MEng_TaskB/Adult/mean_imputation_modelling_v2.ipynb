{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "All libraries imported succesfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup the codespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from termcolor import colored\n",
    "\n",
    "print(colored('\\nAll libraries imported succesfully.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "All datasets imported succesfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import datasets\n",
    "test_data30 = pd.read_excel('test_data.xlsx')\n",
    "train_data_control = pd.read_excel('train_data_control.xlsx')\n",
    "mean_imputed_data_10 = pd.read_csv('mean_imputed_data_10.csv')\n",
    "mean_imputed_data_40 = pd.read_csv('mean_imputed_data_40.csv')\n",
    "mean_imputed_data_70 = pd.read_csv('mean_imputed_data_70.csv')\n",
    "\n",
    "datasets = {\n",
    "'mean_imputed_data_10' : mean_imputed_data_10,\n",
    "'mean_imputed_data_40' : mean_imputed_data_40,\n",
    "'mean_imputed_data_70' : mean_imputed_data_70,\n",
    "}\n",
    "\n",
    "print(colored('\\nAll datasets imported succesfully.', 'green'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target_<=50K'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target_<=50K'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#reverse the one hot encoding of the target variable\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print(dataset_name)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# display(dataset)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# map value depending on conditional statement\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_<=50K\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<=50K\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>50K\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Drop the dummy columns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_ <=50K\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_ >50K\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target_<=50K'"
     ]
    }
   ],
   "source": [
    "#this step is not needed for the mean_imputed data\n",
    "\n",
    "#reverse the one hot encoding of the target variable\n",
    "# for dataset_name, dataset in datasets.items():\n",
    "#     # print(dataset_name)\n",
    "#     # display(dataset)\n",
    "#     # map value depending on conditional statement\n",
    "#     dataset['target'] = dataset['target_ <=50K'].map(lambda x: '<=50K' if x == 1.0 else '>50K')\n",
    "#     # Drop the dummy columns\n",
    "#     dataset.drop(columns=['target_ <=50K', 'target_ >50K'], inplace=True)\n",
    "#     # print(dataset_name)\n",
    "#     # display(dataset)\n",
    "\n",
    "# datasets['train_data_control'] = train_data_control\n",
    "# # print(datasets)\n",
    "\n",
    "# print(colored('\\nEncoding succesfully reversed.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Functions sucsesfully created.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "def kNN_class(train_data, test_data):\n",
    "    evaluation = {}\n",
    "    #train data\n",
    "    features = [col for col in train_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_train = train_data[features].values.tolist()\n",
    "    y_train = train_data['target'].values.tolist()\n",
    "    y_train = [value.strip() for value in y_train]\n",
    "\n",
    "    #test data\n",
    "    features = [col for col in test_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_test = test_data[features].values.tolist()\n",
    "    y_test = test_data['target'].values.tolist()\n",
    "    y_test = [value.strip() for value in y_test]\n",
    "\n",
    "    # Determine optimal k\n",
    "    k_values = [i for i in range (2,10)]\n",
    "    max_score = 0\n",
    "    opt_k = 2\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        score = cross_val_score(knn, x_train, y_train, cv=opt_k)\n",
    "        mean_score = np.mean(score)\n",
    "\n",
    "        if mean_score > max_score:\n",
    "            max_score = mean_score\n",
    "            opt_k = k\n",
    "\n",
    "    #Set and fit model\n",
    "    knn = KNeighborsClassifier(n_neighbors=opt_k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
    "\n",
    "    evaluation = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "def DecisionTree_class(train_data, test_data):\n",
    "    evaluation = {}\n",
    "    #train data\n",
    "    features = [col for col in train_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_train = train_data[features].values.tolist()\n",
    "    y_train = train_data['target'].values.tolist()\n",
    "    y_train = [value.strip() for value in y_train]\n",
    "    \n",
    "    #test data\n",
    "    features = [col for col in test_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_test = test_data[features].values.tolist()\n",
    "    y_test = test_data['target'].values.tolist()\n",
    "    y_test = [value.strip() for value in y_test]\n",
    "\n",
    "    # Determine optimal tree depth\n",
    "    depth_values = [i for i in range(2, 20)]\n",
    "    max_score = 0\n",
    "    optimal_depth = 2\n",
    "\n",
    "    for depth in depth_values:\n",
    "        # print(f'depth: {depth}')\n",
    "        clf = DecisionTreeClassifier(max_depth=depth)\n",
    "        score = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "        # print(f'score: {score}')\n",
    "        mean_score = np.mean(score)\n",
    "        # print(f'mean score: {mean_score}')\n",
    "\n",
    "        if mean_score > max_score:\n",
    "            max_score = mean_score\n",
    "            # print(f'max score: {max_score}')\n",
    "            optimal_depth = depth\n",
    "            # print(f'opt depth: {optimal_depth}')\n",
    "    \n",
    "    # print(f'final depth: {optimal_depth}')\n",
    "\n",
    "    # final modelling\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf = clf.fit(x_train,y_train)\n",
    "    y_pred = dt_clf.predict(x_test)\n",
    "\n",
    "    # performance evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
    " \n",
    "    evaluation = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "        # 'rocauc': rocauc\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "print(colored('\\nFunctions sucsesfully created.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DT depth searcher\n",
    "DecisionTree_class(train_data_control,test_data30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_imputed_data_10':           ID       age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0       9714  0.178082  0.097373       0.533333      0.000000      0.000000   \n",
      "1       1826  0.068493  0.129471       0.533333      1.000000      0.000000   \n",
      "2       9507  0.095890  0.068717       0.533333      0.000000      0.000000   \n",
      "3      27887  0.082192  0.300917       0.533333      0.000000      0.000000   \n",
      "4      13104  0.643836  0.106844       0.400000      0.000000      0.000000   \n",
      "...      ...       ...       ...            ...           ...           ...   \n",
      "22787  29471  0.295744  0.228504       0.933333      0.000000      0.000000   \n",
      "22788  21055  0.520548  0.090279       0.606240      0.010571      0.000000   \n",
      "22789  20870  0.369863  0.123332       0.666667      0.000000      0.307622   \n",
      "22790  29768  0.287671  0.120619       0.606240      0.000000      0.000000   \n",
      "22791  11185  0.397260  0.108866       0.800000      0.000000      0.436639   \n",
      "\n",
      "       hours-per-week  target  \n",
      "0            0.357143   <=50K  \n",
      "1            0.397959    >50K  \n",
      "2            0.397959   <=50K  \n",
      "3            0.402921   <=50K  \n",
      "4            0.397959   <=50K  \n",
      "...               ...     ...  \n",
      "22787        0.402921    >50K  \n",
      "22788        0.193878   <=50K  \n",
      "22789        0.402921   <=50K  \n",
      "22790        0.346939   <=50K  \n",
      "22791        0.500000    >50K  \n",
      "\n",
      "[22792 rows x 8 columns], 'mean_imputed_data_40':           ID       age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0       9714  0.297631  0.097373       0.533333      0.010941      0.000000   \n",
      "1       1826  0.068493  0.120522       0.605119      0.010941      0.000000   \n",
      "2       9507  0.095890  0.068717       0.533333      0.010941      0.000000   \n",
      "3      27887  0.082192  0.300917       0.605119      0.000000      0.000000   \n",
      "4      13104  0.643836  0.120522       0.400000      0.000000      0.000000   \n",
      "...      ...       ...       ...            ...           ...           ...   \n",
      "22787  29471  0.297631  0.120522       0.933333      0.000000      0.000000   \n",
      "22788  21055  0.297631  0.090279       0.600000      0.010941      0.000000   \n",
      "22789  20870  0.297631  0.120522       0.666667      0.000000      0.307622   \n",
      "22790  29768  0.297631  0.120522       0.866667      0.000000      0.000000   \n",
      "22791  11185  0.297631  0.108866       0.800000      0.000000      0.436639   \n",
      "\n",
      "       hours-per-week  target  \n",
      "0            0.402842   <=50K  \n",
      "1            0.397959   <=50K  \n",
      "2            0.402842   <=50K  \n",
      "3            0.397959   <=50K  \n",
      "4            0.397959   <=50K  \n",
      "...               ...     ...  \n",
      "22787        0.500000   <=50K  \n",
      "22788        0.402842   <=50K  \n",
      "22789        0.402842   <=50K  \n",
      "22790        0.402842   <=50K  \n",
      "22791        0.500000   <=50K  \n",
      "\n",
      "[22792 rows x 8 columns], 'mean_imputed_data_70':           ID       age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0       9714  0.299507  0.120840       0.605079      0.010764      0.000000   \n",
      "1       1826  0.068493  0.120840       0.605079      0.010764      0.000000   \n",
      "2       9507  0.095890  0.120840       0.533333      0.010764      0.000000   \n",
      "3      27887  0.299507  0.300917       0.533333      0.010764      0.000000   \n",
      "4      13104  0.299507  0.120840       0.400000      0.010764      0.000000   \n",
      "...      ...       ...       ...            ...           ...           ...   \n",
      "22787  29471  0.299507  0.120840       0.933333      0.000000      0.000000   \n",
      "22788  21055  0.299507  0.120840       0.600000      0.046500      0.000000   \n",
      "22789  20870  0.299507  0.120840       0.605079      0.010764      0.307622   \n",
      "22790  29768  0.287671  0.120840       0.605079      0.010764      0.000000   \n",
      "22791  11185  0.299507  0.120840       0.605079      0.010764      0.000000   \n",
      "\n",
      "       hours-per-week  target  \n",
      "0            0.402621   <=50K  \n",
      "1            0.397959   <=50K  \n",
      "2            0.397959   <=50K  \n",
      "3            0.397959   <=50K  \n",
      "4            0.402621   <=50K  \n",
      "...               ...     ...  \n",
      "22787        0.500000   <=50K  \n",
      "22788        0.193878   <=50K  \n",
      "22789        0.397959   <=50K  \n",
      "22790        0.402621   <=50K  \n",
      "22791        0.402621   <=50K  \n",
      "\n",
      "[22792 rows x 8 columns], 'train_data_control':           ID       age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0       9714  0.178082  0.097373       0.533333        0.0000      0.000000   \n",
      "1       1826  0.068493  0.129471       0.533333        1.0000      0.000000   \n",
      "2       9507  0.095890  0.068717       0.533333        0.0000      0.000000   \n",
      "3      27887  0.082192  0.300917       0.533333        0.0000      0.000000   \n",
      "4      13104  0.643836  0.106844       0.400000        0.0000      0.000000   \n",
      "...      ...       ...       ...            ...           ...           ...   \n",
      "22787  29471  0.273973  0.228504       0.933333        0.0000      0.000000   \n",
      "22788  21055  0.520548  0.090279       0.600000        0.0465      0.000000   \n",
      "22789  20870  0.369863  0.123332       0.666667        0.0000      0.307622   \n",
      "22790  29768  0.287671  0.154971       0.866667        0.0000      0.000000   \n",
      "22791  11185  0.397260  0.108866       0.800000        0.0000      0.436639   \n",
      "\n",
      "       hours-per-week  target  \n",
      "0            0.357143   <=50K  \n",
      "1            0.397959    >50K  \n",
      "2            0.397959   <=50K  \n",
      "3            0.397959   <=50K  \n",
      "4            0.397959   <=50K  \n",
      "...               ...     ...  \n",
      "22787        0.500000    >50K  \n",
      "22788        0.193878   <=50K  \n",
      "22789        0.397959   <=50K  \n",
      "22790        0.346939   <=50K  \n",
      "22791        0.500000    >50K  \n",
      "\n",
      "[22792 rows x 8 columns]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_imputed_data_10</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.812366</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.812366</td>\n",
       "      <td>0.785603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_imputed_data_10</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.785137</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>0.785137</td>\n",
       "      <td>0.772090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_imputed_data_40</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.781042</td>\n",
       "      <td>0.768357</td>\n",
       "      <td>0.781042</td>\n",
       "      <td>0.717674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_imputed_data_40</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.774593</td>\n",
       "      <td>0.745485</td>\n",
       "      <td>0.774593</td>\n",
       "      <td>0.747053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_imputed_data_70</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.762924</td>\n",
       "      <td>0.779608</td>\n",
       "      <td>0.762924</td>\n",
       "      <td>0.661535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_imputed_data_70</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.749616</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.749616</td>\n",
       "      <td>0.715716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_data_control</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.811137</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>0.811137</td>\n",
       "      <td>0.788795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_data_control</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.807452</td>\n",
       "      <td>0.797109</td>\n",
       "      <td>0.807452</td>\n",
       "      <td>0.800397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset_name                          model  accuracy  precision  \\\n",
       "0  mean_imputed_data_10  k-NearestNeighbour_classifier  0.812366   0.799997   \n",
       "1  mean_imputed_data_10        DecisionTree_classifier  0.785137   0.767573   \n",
       "2  mean_imputed_data_40  k-NearestNeighbour_classifier  0.781042   0.768357   \n",
       "3  mean_imputed_data_40        DecisionTree_classifier  0.774593   0.745485   \n",
       "4  mean_imputed_data_70  k-NearestNeighbour_classifier  0.762924   0.779608   \n",
       "5  mean_imputed_data_70        DecisionTree_classifier  0.749616   0.707729   \n",
       "6    train_data_control  k-NearestNeighbour_classifier  0.811137   0.796149   \n",
       "7    train_data_control        DecisionTree_classifier  0.807452   0.797109   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.812366  0.785603  \n",
       "1  0.785137  0.772090  \n",
       "2  0.781042  0.717674  \n",
       "3  0.774593  0.747053  \n",
       "4  0.762924  0.661535  \n",
       "5  0.749616  0.715716  \n",
       "6  0.811137  0.788795  \n",
       "7  0.807452  0.800397  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Model and Evaluation\n",
    "datasets['train_data_control'] = train_data_control\n",
    "print(datasets)\n",
    "results_classification = []\n",
    "\n",
    "# Define a list of classification functions along with their names\n",
    "classification_model = [\n",
    "    ('k-NearestNeighbour_classifier', kNN_class),\n",
    "    ('DecisionTree_classifier', DecisionTree_class)\n",
    "]\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    for model_name, model in classification_model:\n",
    "        try:\n",
    "            results = model(dataset, test_data30)\n",
    "            result_dict = {'dataset_name': dataset_name, 'model': model_name, **results}\n",
    "            results_classification.append(result_dict)\n",
    "        except Exception as e:\n",
    "            error_message = str(e).split('\\n')[0]  \n",
    "            print(f\"Error occurred in {model_name} Classification for dataset_name {dataset_name}: {error_message}\")\n",
    "\n",
    "results_classification_df = pd.DataFrame(results_classification)\n",
    "display(results_classification_df)\n",
    "results_classification_df.to_excel('mean_classification_model_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
