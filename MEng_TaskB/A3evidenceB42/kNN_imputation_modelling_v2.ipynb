{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "All libraries imported succesfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup the codespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from termcolor import colored\n",
    "\n",
    "print(colored('\\nAll libraries imported succesfully.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "All datasets imported succesfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import datasets\n",
    "test_data30 = pd.read_excel('test_data.xlsx')\n",
    "train_data_control = pd.read_excel('train_data_control.xlsx')\n",
    "kNN_imputed_10 = pd.read_csv('kNN_imputed_10.csv')\n",
    "kNN_imputed_40 = pd.read_csv('kNN_imputed_40.csv')\n",
    "kNN_imputed_70 = pd.read_csv('kNN_imputed_70.csv')\n",
    "\n",
    "datasets = {\n",
    "'kNN_imputed_10' : kNN_imputed_10,\n",
    "'kNN_imputed_40' : kNN_imputed_40,\n",
    "'kNN_imputed_70' : kNN_imputed_70,\n",
    "}\n",
    "\n",
    "print(colored('\\nAll datasets imported succesfully.', 'green'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Encoding succesfully reversed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#reverse the one hot encoding of the target variable\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    # print(dataset_name)\n",
    "    # display(dataset)\n",
    "    # map value depending on conditional statement\n",
    "    dataset['target'] = dataset['target_ <=50K'].map(lambda x: '<=50K' if x == 1.0 else '>50K')\n",
    "    # Drop the dummy columns\n",
    "    dataset.drop(columns=['target_ <=50K', 'target_ >50K'], inplace=True)\n",
    "    # print(dataset_name)\n",
    "    # display(dataset)\n",
    "\n",
    "datasets['train_data_control'] = train_data_control\n",
    "# print(datasets)\n",
    "\n",
    "print(colored('\\nEncoding succesfully reversed.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Functions sucsesfully created.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "def kNN_class(train_data, test_data):\n",
    "    evaluation = {}\n",
    "    #train data\n",
    "    features = [col for col in train_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_train = train_data[features].values.tolist()\n",
    "    y_train = train_data['target'].values.tolist()\n",
    "    y_train = [value.strip() for value in y_train]\n",
    "\n",
    "    #test data\n",
    "    features = [col for col in test_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_test = test_data[features].values.tolist()\n",
    "    y_test = test_data['target'].values.tolist()\n",
    "    y_test = [value.strip() for value in y_test]\n",
    "\n",
    "    # Determine optimal k\n",
    "    k_values = [i for i in range (2,10)]\n",
    "    max_score = 0\n",
    "    opt_k = 2\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        score = cross_val_score(knn, x_train, y_train, cv=opt_k)\n",
    "        mean_score = np.mean(score)\n",
    "\n",
    "        if mean_score > max_score:\n",
    "            max_score = mean_score\n",
    "            opt_k = k\n",
    "\n",
    "    #Set and fit model\n",
    "    knn = KNeighborsClassifier(n_neighbors=opt_k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
    "\n",
    "    evaluation = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "def DecisionTree_class(train_data, test_data):\n",
    "    evaluation = {}\n",
    "    #train data\n",
    "    features = [col for col in train_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_train = train_data[features].values.tolist()\n",
    "    y_train = train_data['target'].values.tolist()\n",
    "    y_train = [value.strip() for value in y_train]\n",
    "    \n",
    "    #test data\n",
    "    features = [col for col in test_data.columns if col != 'target' and col != 'ID']\n",
    "    # print(features)\n",
    "    x_test = test_data[features].values.tolist()\n",
    "    y_test = test_data['target'].values.tolist()\n",
    "    y_test = [value.strip() for value in y_test]\n",
    "\n",
    "    # Determine optimal tree depth\n",
    "    depth_values = [i for i in range(2, 20)]\n",
    "    max_score = 0\n",
    "    optimal_depth = 2\n",
    "\n",
    "    for depth in depth_values:\n",
    "        # print(f'depth: {depth}')\n",
    "        clf = DecisionTreeClassifier(max_depth=depth)\n",
    "        score = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "        # print(f'score: {score}')\n",
    "        mean_score = np.mean(score)\n",
    "        # print(f'mean score: {mean_score}')\n",
    "\n",
    "        if mean_score > max_score:\n",
    "            max_score = mean_score\n",
    "            # print(f'max score: {max_score}')\n",
    "            optimal_depth = depth\n",
    "            # print(f'opt depth: {optimal_depth}')\n",
    "    \n",
    "    # print(f'final depth: {optimal_depth}')\n",
    "\n",
    "    # final modelling\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf = clf.fit(x_train,y_train)\n",
    "    y_pred = dt_clf.predict(x_test)\n",
    "\n",
    "    # performance evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
    " \n",
    "    evaluation = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "        # 'rocauc': rocauc\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "print(colored('\\nFunctions sucsesfully created.', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 2\n",
      "score: [0.80394737 0.79912281 0.79552435 0.79991224 0.79815709 0.80035103\n",
      " 0.8095656  0.79991224 0.79640193 0.8016674 ]\n",
      "mean score: 0.8004562057843161\n",
      "max score: 0.8004562057843161\n",
      "opt depth: 2\n",
      "depth: 3\n",
      "score: [0.80789474 0.80921053 0.79727951 0.80824923 0.79815709 0.81790259\n",
      " 0.80210619 0.80824923 0.79201404 0.80122861]\n",
      "mean score: 0.8042291748458466\n",
      "max score: 0.8042291748458466\n",
      "opt depth: 3\n",
      "depth: 4\n",
      "score: [0.82631579 0.81359649 0.81000439 0.81570864 0.81526986 0.8174638\n",
      " 0.82272927 0.81790259 0.80912681 0.81439228]\n",
      "mean score: 0.8162509911241465\n",
      "max score: 0.8162509911241465\n",
      "opt depth: 4\n",
      "depth: 5\n",
      "score: [0.83859649 0.83114035 0.82843352 0.82667837 0.82755595 0.84159719\n",
      " 0.83194384 0.83282141 0.81790259 0.825362  ]\n",
      "mean score: 0.8302031708274635\n",
      "max score: 0.8302031708274635\n",
      "opt depth: 5\n",
      "depth: 6\n",
      "score: [0.83815789 0.83201754 0.8293111  0.82580079 0.82974989 0.8411584\n",
      " 0.83238262 0.83501536 0.8214129  0.82360685]\n",
      "mean score: 0.8308613349961125\n",
      "max score: 0.8308613349961125\n",
      "opt depth: 6\n",
      "depth: 7\n",
      "score: [0.84342105 0.82719298 0.82492321 0.82316806 0.83018868 0.84379114\n",
      " 0.83238262 0.84247477 0.81658622 0.825362  ]\n",
      "mean score: 0.8309490735394871\n",
      "max score: 0.8309490735394871\n",
      "opt depth: 7\n",
      "depth: 8\n",
      "score: [0.84517544 0.82894737 0.83106626 0.82755595 0.83238262 0.84203598\n",
      " 0.83677051 0.84159719 0.82272927 0.82667837]\n",
      "mean score: 0.8334938954450628\n",
      "max score: 0.8334938954450628\n",
      "opt depth: 8\n",
      "depth: 9\n",
      "score: [0.84254386 0.83070175 0.82667837 0.82711716 0.83369899 0.84379114\n",
      " 0.83457657 0.83808688 0.81921896 0.82580079]\n",
      "mean score: 0.8322214460020169\n",
      "depth: 10\n",
      "score: [0.84298246 0.82763158 0.82316806 0.8293111  0.83106626 0.84203598\n",
      " 0.8372093  0.83589294 0.81965774 0.82448442]\n",
      "mean score: 0.8313439835877541\n",
      "depth: 11\n",
      "score: [0.83903509 0.82412281 0.82360685 0.82667837 0.82448442 0.84379114\n",
      " 0.83194384 0.83589294 0.81175954 0.82404563]\n",
      "mean score: 0.8285360615228285\n",
      "depth: 12\n",
      "score: [0.83377193 0.81929825 0.81658622 0.82097411 0.82272927 0.83808688\n",
      " 0.83018868 0.83501536 0.80781044 0.82053532]\n",
      "mean score: 0.8244996458896254\n",
      "depth: 13\n",
      "score: [0.82894737 0.81140351 0.80517771 0.81921896 0.8174638  0.83062747\n",
      " 0.82755595 0.82974989 0.80254498 0.81614743]\n",
      "mean score: 0.8188837055341291\n",
      "depth: 14\n",
      "score: [0.8254386  0.80833333 0.81044318 0.8174638  0.81439228 0.8293111\n",
      " 0.82623958 0.8214129  0.80473892 0.81483107]\n",
      "mean score: 0.8172604751237461\n",
      "depth: 15\n",
      "score: [0.81973684 0.80614035 0.79859588 0.81483107 0.81044318 0.82316806\n",
      " 0.82448442 0.81921896 0.79464677 0.80912681]\n",
      "mean score: 0.8120392331200973\n",
      "depth: 16\n",
      "score: [0.81359649 0.79780702 0.79464677 0.81658622 0.81263712 0.81834138\n",
      " 0.81790259 0.81921896 0.7898201  0.80517771]\n",
      "mean score: 0.8085734355634588\n",
      "depth: 17\n",
      "score: [0.81008772 0.79605263 0.79552435 0.81395349 0.80517771 0.80912681\n",
      " 0.81263712 0.8135147  0.79464677 0.7977183 ]\n",
      "mean score: 0.8048439604935991\n",
      "depth: 18\n",
      "score: [0.80745614 0.79780702 0.78279947 0.80868802 0.80342255 0.80430013\n",
      " 0.80912681 0.8135147  0.79333041 0.79991224]\n",
      "mean score: 0.8020357497517377\n",
      "depth: 19\n",
      "score: [0.80087719 0.78903509 0.77972795 0.79859588 0.79859588 0.80254498\n",
      " 0.79991224 0.80737165 0.78630978 0.79859588]\n",
      "mean score: 0.7961566515015049\n",
      "final depth: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8074521445388474,\n",
       " 'precision': 0.7971478220235069,\n",
       " 'recall': 0.8074521445388474,\n",
       " 'f1': 0.8004348549605133}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test DT depth searcher\n",
    "DecisionTree_class(train_data_control,test_data30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_imputed_10</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.806633</td>\n",
       "      <td>0.791143</td>\n",
       "      <td>0.806633</td>\n",
       "      <td>0.792501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN_imputed_10</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.784318</td>\n",
       "      <td>0.783021</td>\n",
       "      <td>0.784318</td>\n",
       "      <td>0.783654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN_imputed_40</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.566588</td>\n",
       "      <td>0.754949</td>\n",
       "      <td>0.566588</td>\n",
       "      <td>0.594846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kNN_imputed_40</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.612038</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>0.612038</td>\n",
       "      <td>0.640473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN_imputed_70</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.261644</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.261644</td>\n",
       "      <td>0.145689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kNN_imputed_70</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.319582</td>\n",
       "      <td>0.696035</td>\n",
       "      <td>0.319582</td>\n",
       "      <td>0.268210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_data_control</td>\n",
       "      <td>k-NearestNeighbour_classifier</td>\n",
       "      <td>0.811137</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>0.811137</td>\n",
       "      <td>0.788795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_data_control</td>\n",
       "      <td>DecisionTree_classifier</td>\n",
       "      <td>0.807759</td>\n",
       "      <td>0.797579</td>\n",
       "      <td>0.807759</td>\n",
       "      <td>0.800848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset_name                          model  accuracy  precision  \\\n",
       "0      kNN_imputed_10  k-NearestNeighbour_classifier  0.806633   0.791143   \n",
       "1      kNN_imputed_10        DecisionTree_classifier  0.784318   0.783021   \n",
       "2      kNN_imputed_40  k-NearestNeighbour_classifier  0.566588   0.754949   \n",
       "3      kNN_imputed_40        DecisionTree_classifier  0.612038   0.755536   \n",
       "4      kNN_imputed_70  k-NearestNeighbour_classifier  0.261644   0.721854   \n",
       "5      kNN_imputed_70        DecisionTree_classifier  0.319582   0.696035   \n",
       "6  train_data_control  k-NearestNeighbour_classifier  0.811137   0.796149   \n",
       "7  train_data_control        DecisionTree_classifier  0.807759   0.797579   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.806633  0.792501  \n",
       "1  0.784318  0.783654  \n",
       "2  0.566588  0.594846  \n",
       "3  0.612038  0.640473  \n",
       "4  0.261644  0.145689  \n",
       "5  0.319582  0.268210  \n",
       "6  0.811137  0.788795  \n",
       "7  0.807759  0.800848  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Model and Evaluation\n",
    "results_classification = []\n",
    "\n",
    "# Define a list of classification functions along with their names\n",
    "classification_model = [\n",
    "    ('k-NearestNeighbour_classifier', kNN_class),\n",
    "    ('DecisionTree_classifier', DecisionTree_class)\n",
    "]\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    for model_name, model in classification_model:\n",
    "        try:\n",
    "            results = model(dataset, test_data30)\n",
    "            result_dict = {'dataset_name': dataset_name, 'model': model_name, **results}\n",
    "            results_classification.append(result_dict)\n",
    "        except Exception as e:\n",
    "            error_message = str(e).split('\\n')[0]  \n",
    "            print(f\"Error occurred in {model_name} Classification for dataset_name {dataset_name}: {error_message}\")\n",
    "\n",
    "results_classification_df = pd.DataFrame(results_classification)\n",
    "display(results_classification_df)\n",
    "results_classification_df.to_excel('classification_model_results2.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
